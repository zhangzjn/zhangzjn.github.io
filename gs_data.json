{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "2hA4X9wAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Jiangning Zhang (张江宁)", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=2hA4X9wAAAAJ&citpid=3", "affiliation": "Youtu Lab, Tencent | Zhejiang University", "organization": 1118375729466322660, "interests": ["LLM Agent | Video Generation"], "email_domain": "@zju.edu.cn", "homepage": "https://zhangzjn.github.io/", "citedby": 4675, "publications": {"2hA4X9wAAAAJ:uWQEDVKXjbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rethinking mobile block for efficient attention-based models", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:uWQEDVKXjbEC", "num_citations": 305, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8399801815353872086,6803692528838506853,4462447219040254297,17660248115421671253", "cites_id": ["8399801815353872086", "6803692528838506853", "4462447219040254297", "17660248115421671253"]}, "2hA4X9wAAAAJ:UxriW0iASnsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Omni-frequency channel-selection representations for unsupervised anomaly detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:UxriW0iASnsC", "num_citations": 237, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15876710250266998666", "cites_id": ["15876710250266998666"]}, "2hA4X9wAAAAJ:XiSMed-E-HIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning by analogy: Reliable supervision from transformations for unsupervised optical flow estimation", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:XiSMed-E-HIC", "num_citations": 230, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3875015729190234590", "cites_id": ["3875015729190234590"]}, "2hA4X9wAAAAJ:ldfaerwXgEUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards open vocabulary learning: A survey", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ldfaerwXgEUC", "num_citations": 226, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4374069864889678520", "cites_id": ["4374069864889678520"]}, "2hA4X9wAAAAJ:SP6oXDckpogC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal industrial anomaly detection via hybrid fusion", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:SP6oXDckpogC", "num_citations": 199, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8940602570027713712,2540830192280547690", "cites_id": ["8940602570027713712", "2540830192280547690"]}, "2hA4X9wAAAAJ:eJXPG6dFmWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Diffusion-Based Framework for Multi-Class Anomaly Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:eJXPG6dFmWUC", "num_citations": 197, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4516755124680140750", "cites_id": ["4516755124680140750"]}, "2hA4X9wAAAAJ:p2g8aNsByqUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Freenet: Multi-identity face reenactment", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:p2g8aNsByqUC", "num_citations": 179, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11676370670744214493,14143495475025615130", "cites_id": ["11676370670744214493", "14143495475025615130"]}, "2hA4X9wAAAAJ:BqipwSGYUEgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "APRIL-GAN: A Zero-/Few-Shot Anomaly Classification and Segmentation Method", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:BqipwSGYUEgC", "num_citations": 175, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1984569996728884691,1670056311724797007", "cites_id": ["1984569996728884691", "1670056311724797007"]}, "2hA4X9wAAAAJ:t7zJ5fGR-2UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Point cloud mamba: Point cloud learning via state space model", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:t7zJ5fGR-2UC", "num_citations": 145, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11650303125677654154", "cites_id": ["11650303125677654154"]}, "2hA4X9wAAAAJ:mvPsJ3kp5DgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Anomalydiffusion: Few-shot anomaly image generation with diffusion model", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:mvPsJ3kp5DgC", "num_citations": 139, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15920211044737566150", "cites_id": ["15920211044737566150"]}, "2hA4X9wAAAAJ:UHK10RUVsp4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mambaad: Exploring state space models for multi-class unsupervised anomaly detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:UHK10RUVsp4C", "num_citations": 125, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15481876724486702892", "cites_id": ["15481876724486702892"]}, "2hA4X9wAAAAJ:q3oQSFYPqjQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real-IAD: A Real-World Multi-View Dataset for Benchmarking Versatile Industrial Anomaly Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:q3oQSFYPqjQC", "num_citations": 115, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5525112057645376510", "cites_id": ["5525112057645376510"]}, "2hA4X9wAAAAJ:_Re3VWB3Y0AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaclip: Adapting clip with hybrid learnable prompts for zero-shot anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:_Re3VWB3Y0AC", "num_citations": 106, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14822412996516810335", "cites_id": ["14822412996516810335"]}, "2hA4X9wAAAAJ:V3AGJWp-ZtQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deepfake Generation and Detection: A Benchmark and Survey", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:V3AGJWp-ZtQC", "num_citations": 101, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9827397824432092836", "cites_id": ["9827397824432092836"]}, "2hA4X9wAAAAJ:WbkHhVStYXYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Region-aware face swapping", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:WbkHhVStYXYC", "num_citations": 88, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12630937752246463171", "cites_id": ["12630937752246463171"]}, "2hA4X9wAAAAJ:ZfRJV9d4-WMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Clip-ad: A language-guided staged dual-path model for zero-shot anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ZfRJV9d4-WMC", "num_citations": 80, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8002141840995702613", "cites_id": ["8002141840995702613"]}, "2hA4X9wAAAAJ:zA6iFVUQeVQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Remembering Normality: Memory-guided Knowledge Distillation for Unsupervised Anomaly Detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:zA6iFVUQeVQC", "num_citations": 77, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6873568589231201245", "cites_id": ["6873568589231201245"]}, "2hA4X9wAAAAJ:CHSYGLWDkRkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A survey on visual anomaly detection: Challenge, approach, and prospect", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:CHSYGLWDkRkC", "num_citations": 73, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15683395947501387504", "cites_id": ["15683395947501387504"]}, "2hA4X9wAAAAJ:D03iK_w7-QYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PortraitBooth: A Versatile Portrait Model for Fast Identity-preserved Personalization", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:D03iK_w7-QYC", "num_citations": 69, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2807970536527593463", "cites_id": ["2807970536527593463"]}, "2hA4X9wAAAAJ:dTyEYWd-f8wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MotionBooth: Motion-Aware Customized Text-to-Video Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:dTyEYWd-f8wC", "num_citations": 66, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5217561798098030587", "cites_id": ["5217561798098030587"]}, "2hA4X9wAAAAJ:f2IySw72cVMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring plain vit reconstruction for multi-class unsupervised anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:f2IySw72cVMC", "num_citations": 64, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1180170355200597287,1075116936351398361", "cites_id": ["1180170355200597287", "1075116936351398361"]}, "2hA4X9wAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Designing One Unified Framework for High-Fidelity Face Reenactment and Swapping", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:9ZlFYXVOiuMC", "num_citations": 58, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10517210380745041646", "cites_id": ["10517210380745041646"]}, "2hA4X9wAAAAJ:ZHo1McVdvXMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sfnet: Faster and Accurate Semantic Segmentation Via Semantic Flow", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ZHo1McVdvXMC", "num_citations": 57, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=423028739487429125", "cites_id": ["423028739487429125"]}, "2hA4X9wAAAAJ:k_IJM867U9cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "High-fidelity Generalized Emotional Talking Face Generation with Multi-modal Emotion Space Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:k_IJM867U9cC", "num_citations": 57, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14284243388686741119", "cites_id": ["14284243388686741119"]}, "2hA4X9wAAAAJ:tOudhMTPpwUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mixteacher: Mining promising labels with mixed scale teacher for semi-supervised object detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tOudhMTPpwUC", "num_citations": 54, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=360005364412013411", "cites_id": ["360005364412013411"]}, "2hA4X9wAAAAJ:RGFaLdJalmkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dtvnet: Dynamic time-lapse video generation via single still image", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:RGFaLdJalmkC", "num_citations": 53, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8543456608729588740,12995822360434038988", "cites_id": ["8543456608729588740", "12995822360434038988"]}, "2hA4X9wAAAAJ:GnPB-g6toBAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RFNet: recurrent forward network for dense point cloud completion", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:GnPB-g6toBAC", "num_citations": 50, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1369368557383473552", "cites_id": ["1369368557383473552"]}, "2hA4X9wAAAAJ:Tiz5es2fbqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Realistic face reenactment via self-supervised disentangling of identity and pose", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:Tiz5es2fbqcC", "num_citations": 50, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2172292118953588179", "cites_id": ["2172292118953588179"]}, "2hA4X9wAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Eatformer: Improving vision transformer inspired by evolutionary algorithm", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:qxL8FJ1GzNcC", "num_citations": 47, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14151647974405698917", "cites_id": ["14151647974405698917"]}, "2hA4X9wAAAAJ:fEOibwPWpKIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Face-Adapter for Pre-trained Diffusion Models with Fine-Grained ID and Attribute Control", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:fEOibwPWpKIC", "num_citations": 46, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17368182402162268103", "cites_id": ["17368182402162268103"]}, "2hA4X9wAAAAJ:RYcK_YlVTxYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning-based hand motion capture and understanding in assembly process", "pub_year": "2018"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:RYcK_YlVTxYC", "num_citations": 37, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17957912339505702803", "cites_id": ["17957912339505702803"]}, "2hA4X9wAAAAJ:tzM49s52ZIMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Freemotion: A unified framework for number-free text-to-motion synthesis", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tzM49s52ZIMC", "num_citations": 36, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4441956630149334493", "cites_id": ["4441956630149334493"]}, "2hA4X9wAAAAJ:kzcrU_BdoSEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GPT-4V-AD: Exploring Grounding Potential of VQA-Oriented GPT-4V for Zero-Shot Anomaly Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:kzcrU_BdoSEC", "num_citations": 36, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3392113585885798646,8528002381465121274", "cites_id": ["3392113585885798646", "8528002381465121274"]}, "2hA4X9wAAAAJ:D_sINldO8mEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rethinking Reverse Distillation for Multi-Modal Anomaly Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:D_sINldO8mEC", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8372764793963584341", "cites_id": ["8372764793963584341"]}, "2hA4X9wAAAAJ:-_dYPAW6P2MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-supervised feature adaptation for 3d industrial anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:-_dYPAW6P2MC", "num_citations": 33, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11021572587767727927", "cites_id": ["11021572587767727927"]}, "2hA4X9wAAAAJ:XiVPGOgt02cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MotionMaster: Training-free Camera Motion Transfer For Video Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:XiVPGOgt02cC", "num_citations": 33, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12403200263986038711,16826424060222634744", "cites_id": ["12403200263986038711", "16826424060222634744"]}, "2hA4X9wAAAAJ:b0M2c_1WBrUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards language-driven video inpainting via multimodal large language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:b0M2c_1WBrUC", "num_citations": 32, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8854937429748086141", "cites_id": ["8854937429748086141"]}, "2hA4X9wAAAAJ:vRqMK49ujn8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Iterative few-shot semantic segmentation from image label text", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:vRqMK49ujn8C", "num_citations": 30, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7445612649408352675", "cites_id": ["7445612649408352675"]}, "2hA4X9wAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "3QNet: 3D Point Cloud Geometry Quantization Compression Network", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ZeXyd9-uunAC", "num_citations": 29, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10354066383229872446", "cites_id": ["10354066383229872446"]}, "2hA4X9wAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multilevel Spatial-Temporal Feature Aggregation for Video Object Detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:4TOpqqG69KYC", "num_citations": 29, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=915144743605869208", "cites_id": ["915144743605869208"]}, "2hA4X9wAAAAJ:nb7KW1ujOQ8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Reference twice: A simple and unified baseline for few-shot instance segmentation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:nb7KW1ujOQ8C", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5798636040124543876", "cites_id": ["5798636040124543876"]}, "2hA4X9wAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning with Noisy labels via Self-supervised Adversarial Noisy Masking", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:e5wmG9Sq2KIC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14616143760826087984", "cites_id": ["14616143760826087984"]}, "2hA4X9wAAAAJ:t6usbXjVLHcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Pointrwkv: Efficient rwkv-like model for hierarchical point cloud learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:t6usbXjVLHcC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11075235487468564374", "cites_id": ["11075235487468564374"]}, "2hA4X9wAAAAJ:VLnqNzywnoUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mobilemamba: Lightweight multi-receptive visual mamba network", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:VLnqNzywnoUC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9415738422234865861", "cites_id": ["9415738422234865861"]}, "2hA4X9wAAAAJ:NJ774b8OgUMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fitdit: Advancing the authentic garment details for high-fidelity virtual try-on", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:NJ774b8OgUMC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11863285159648257198", "cites_id": ["11863285159648257198"]}, "2hA4X9wAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Analogous to evolutionary algorithm: Designing a unified sequence model", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:kNdYIx-mwKoC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12574250028327747897", "cites_id": ["12574250028327747897"]}, "2hA4X9wAAAAJ:z_wVstp3MssC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sonic: Shifting focus to global audio perception in portrait animation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:z_wVstp3MssC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15991424711205920935", "cites_id": ["15991424711205920935"]}, "2hA4X9wAAAAJ:08ZZubdj9fEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal-driven talking face generation, face swapping, diffusion model", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:08ZZubdj9fEC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10621497816434551698,729797935432971854", "cites_id": ["10621497816434551698", "729797935432971854"]}, "2hA4X9wAAAAJ:tKAzc9rXhukC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A comprehensive library for benchmarking multi-class visual anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tKAzc9rXhukC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3639034251259405294,17604605278076559698", "cites_id": ["3639034251259405294", "17604605278076559698"]}, "2hA4X9wAAAAJ:AXPGKjj_ei8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vividpose: Advancing stable video diffusion for realistic human image animation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:AXPGKjj_ei8C", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6016083296626963487", "cites_id": ["6016083296626963487"]}, "2hA4X9wAAAAJ:rO6llkc54NcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:rO6llkc54NcC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2137844415567478150", "cites_id": ["2137844415567478150"]}, "2hA4X9wAAAAJ:g5m5HwL7SMYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PVG: Progressive Vision Graph for Vision Recognition", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:g5m5HwL7SMYC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17736928290896075046", "cites_id": ["17736928290896075046"]}, "2hA4X9wAAAAJ:fPk4N6BV_jEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Better\" CMOS\" Produces Clearer Images: Learning Space-Variant Blur Estimation for Blind Image Super-Resolution", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:fPk4N6BV_jEC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3682948729479689165,14923800501068358589", "cites_id": ["3682948729479689165", "14923800501068358589"]}, "2hA4X9wAAAAJ:tS2w5q8j5-wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Scsnet: An efficient paradigm for learning simultaneously image colorization and super-resolution", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tS2w5q8j5-wC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10250034740894351500", "cites_id": ["10250034740894351500"]}, "2hA4X9wAAAAJ:dQ2og3OwTAUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Osv: One step is enough for high-quality image to video generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:dQ2og3OwTAUC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17727228944916732684", "cites_id": ["17727228944916732684"]}, "2hA4X9wAAAAJ:5ugPr518TE4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SuperSVG: Superpixel-based scalable vector graphics synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:5ugPr518TE4C", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16395703982419708695", "cites_id": ["16395703982419708695"]}, "2hA4X9wAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adding before pruning: Sparse filter fusion for deep convolutional neural networks via auxiliary attention", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:7PzlFSSx8tAC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11443840263675098986", "cites_id": ["11443840263675098986"]}, "2hA4X9wAAAAJ:bFI3QPDXJZMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Generalist FaceX via Learning Unified Facial Representation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:bFI3QPDXJZMC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1518916058955134215", "cites_id": ["1518916058955134215"]}, "2hA4X9wAAAAJ:lSLTfruPkqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Calibrated Teacher for Sparsely Annotated Object Detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:lSLTfruPkqcC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9299468912113782427", "cites_id": ["9299468912113782427"]}, "2hA4X9wAAAAJ:K3LRdlH-MEoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Apb2face: Audio-guided face reenactment with auxiliary pose and blink signals", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:K3LRdlH-MEoC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17109399904647244610", "cites_id": ["17109399904647244610"]}, "2hA4X9wAAAAJ:5Ul4iDaHHb8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Explore in-context segmentation via latent diffusion models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:5Ul4iDaHHb8C", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11945616096981116533", "cites_id": ["11945616096981116533"]}, "2hA4X9wAAAAJ:bnK-pcrLprsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning feature inversion for multi-class anomaly detection under general-purpose coco-ad benchmark", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:bnK-pcrLprsC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17322629230626563646", "cites_id": ["17322629230626563646"]}, "2hA4X9wAAAAJ:j8SEvjWlNXcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unveil inversion and invariance in flow transformer for versatile image editing", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:j8SEvjWlNXcC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=819932006508377753", "cites_id": ["819932006508377753"]}, "2hA4X9wAAAAJ:JQOojiI6XY0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Llava-kd: A framework of distilling multimodal large language models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:JQOojiI6XY0C", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5300045817686583880", "cites_id": ["5300045817686583880"]}, "2hA4X9wAAAAJ:738O_yMBCRsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real-time audio-guided multi-face reenactment", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:738O_yMBCRsC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10955743015947891050,18434141885400621884", "cites_id": ["10955743015947891050", "18434141885400621884"]}, "2hA4X9wAAAAJ:eMMeJKvmdy0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M3dm-nr: Rgb-3d noisy-resistant industrial anomaly detection via multimodal denoising", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:eMMeJKvmdy0C", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5223306447103109872", "cites_id": ["5223306447103109872"]}, "2hA4X9wAAAAJ:2KloaMYe4IUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DiffuMatting: Synthesizing Arbitrary Objects with Matting-level Annotation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:2KloaMYe4IUC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7118312767467766590", "cites_id": ["7118312767467766590"]}, "2hA4X9wAAAAJ:blknAaTinKkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Global-aware Kernel for Image Harmonization", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:blknAaTinKkC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4311617877515083361", "cites_id": ["4311617877515083361"]}, "2hA4X9wAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaptive Recurrent Forward Network for Dense Point Cloud Completion", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:mVmsd5A6BfQC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11440181636670610641", "cites_id": ["11440181636670610641"]}, "2hA4X9wAAAAJ:LjlpjdlvIbIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Licrocc: Teach radar for accurate semantic occupancy prediction using lidar and camera", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:LjlpjdlvIbIC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13527183636746229220", "cites_id": ["13527183636746229220"]}, "2hA4X9wAAAAJ:uc_IGeMz5qoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rwkv-unet: Improving unet with long-range cooperation for effective medical image segmentation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:uc_IGeMz5qoC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5687313393756329486", "cites_id": ["5687313393756329486"]}, "2hA4X9wAAAAJ:35r97b3x0nAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TexDreamer: Towards Zero-Shot High-Fidelity 3D Human Texture Generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:35r97b3x0nAC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10346512206618482675", "cites_id": ["10346512206618482675"]}, "2hA4X9wAAAAJ:1qzjygNMrQYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TransAVS: End-to-End Audio-Visual Segmentation with Transformer", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:1qzjygNMrQYC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4232256084207778991,11454923689554224673", "cites_id": ["4232256084207778991", "11454923689554224673"]}, "2hA4X9wAAAAJ:eflP2zaiRacC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dmad: Dual memory bank for real-world anomaly detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:eflP2zaiRacC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8989284569078344959", "cites_id": ["8989284569078344959"]}, "2hA4X9wAAAAJ:geHnlv5EZngC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dual-path Frequency Discriminators for Few-shot Anomaly Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:geHnlv5EZngC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8853579622716673300", "cites_id": ["8853579622716673300"]}, "2hA4X9wAAAAJ:3s1wT3WcHBgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Toward High Quality Facial Representation Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:3s1wT3WcHBgC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16502864466572204955", "cites_id": ["16502864466572204955"]}, "2hA4X9wAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning To Measure the Point Cloud Reconstruction Loss in a Representation Space", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:hMod-77fHWUC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8828344287570774351,3635818321333649508", "cites_id": ["8828344287570774351", "3635818321333649508"]}, "2hA4X9wAAAAJ:xtRiw3GOFMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with Fine-Grained Feature Representation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:xtRiw3GOFMkC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12669725982803146844", "cites_id": ["12669725982803146844"]}, "2hA4X9wAAAAJ:ipzZ9siozwsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Are they the same? exploring visual correspondence shortcomings of multimodal llms", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ipzZ9siozwsC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9461818450777280555", "cites_id": ["9461818450777280555"]}, "2hA4X9wAAAAJ:ZuybSZzF8UAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MDT-A2G: Exploring Masked Diffusion Transformers for Co-Speech Gesture Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ZuybSZzF8UAC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5415177780427279430", "cites_id": ["5415177780427279430"]}, "2hA4X9wAAAAJ:N5tVd3kTz84C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MambaGesture: Enhancing Co-Speech Gesture Generation with Mamba and Disentangled Multi-Modality Fusion", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:N5tVd3kTz84C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2611012089890276440", "cites_id": ["2611012089890276440"]}, "2hA4X9wAAAAJ:EkHepimYqZsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Realtalk: Real-time and realistic audio-driven face generation with 3d facial prior-guided identity alignment network", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:EkHepimYqZsC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6659931522436241189", "cites_id": ["6659931522436241189"]}, "2hA4X9wAAAAJ:J-pR_7NvFogC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-supervised likelihood estimation with energy guidance for anomaly segmentation in urban scenes", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:J-pR_7NvFogC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3871129052633933760", "cites_id": ["3871129052633933760"]}, "2hA4X9wAAAAJ:WqliGbK-hY8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning multi-view anomaly detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:WqliGbK-hY8C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1387207311189402543", "cites_id": ["1387207311189402543"]}, "2hA4X9wAAAAJ:e_rmSamDkqQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual document understanding and question answering: A multi-agent collaboration framework with test-time scaling", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:e_rmSamDkqQC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=970663921266525040", "cites_id": ["970663921266525040"]}, "2hA4X9wAAAAJ:g3aElNc5_aQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TIMotion: Temporal and Interactive Framework for Efficient Human-Human Motion Generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:g3aElNc5_aQC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11937808497014036628", "cites_id": ["11937808497014036628"]}, "2hA4X9wAAAAJ:LPZeul_q3PIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Pointseg: A training-free paradigm for 3d scene segmentation via foundation models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:LPZeul_q3PIC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16656195211769167087", "cites_id": ["16656195211769167087"]}, "2hA4X9wAAAAJ:uLbwQdceFCQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Llava-vsd: Large language-and-vision assistant for visual spatial description", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:uLbwQdceFCQC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11755256025716233943", "cites_id": ["11755256025716233943"]}, "2hA4X9wAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fast Point Cloud Sampling Network", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:L8Ckcad2t8MC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8849514971316997554", "cites_id": ["8849514971316997554"]}, "2hA4X9wAAAAJ:P5F9QuxV20EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MMoFusion: Multi-modal co-speech motion generation with diffusion model", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:P5F9QuxV20EC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6203521454410525010", "cites_id": ["6203521454410525010"]}, "2hA4X9wAAAAJ:BUYA1_V_uYcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "High-efficient diffusion model fine-tuning with progressive sparse low-rank adaptation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:BUYA1_V_uYcC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1648775452550295302", "cites_id": ["1648775452550295302"]}, "2hA4X9wAAAAJ:tkaPQYYpVKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Anymaker: Zero-shot general object customization via decoupled dual-level id injection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tkaPQYYpVKoC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1234404490701404384", "cites_id": ["1234404490701404384"]}, "2hA4X9wAAAAJ:Fu2w8maKXqMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fetch and Forge: Efficient Dataset Condensation for Object Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:Fu2w8maKXqMC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7994250064571555197", "cites_id": ["7994250064571555197"]}, "2hA4X9wAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Resolution-Free Point Cloud Sampling Network with Data Distillation", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:dhFuZR0502QC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9525132096843510227", "cites_id": ["9525132096843510227"]}, "2hA4X9wAAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning to Train a Point Cloud Reconstruction Network Without Matching", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:QIV2ME_5wuYC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14413331854945255272", "cites_id": ["14413331854945255272"]}, "2hA4X9wAAAAJ:sSrBHYA8nusC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning hierarchical and efficient Person re-identification for robotic navigation", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:sSrBHYA8nusC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17041763138249409154,15631123984536072886", "cites_id": ["17041763138249409154", "15631123984536072886"]}, "2hA4X9wAAAAJ:tuHXwOkdijsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UltraVideo: High-Quality UHD Video Dataset with Comprehensive Captions", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tuHXwOkdijsC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8830646779127013911", "cites_id": ["8830646779127013911"]}, "2hA4X9wAAAAJ:TIZ-Mc8IlK0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "So-Fake: Benchmarking and Explaining Social Media Image Forgery Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:TIZ-Mc8IlK0C", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16026523829622046068", "cites_id": ["16026523829622046068"]}, "2hA4X9wAAAAJ:0KyAp5RtaNEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Improving autoregressive visual generation with cluster-oriented token prediction", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:0KyAp5RtaNEC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=917972641444598901", "cites_id": ["917972641444598901"]}, "2hA4X9wAAAAJ:_Ybze24A_UAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Textual decomposition then sub-motion-space scattering for open-vocabulary motion generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:_Ybze24A_UAC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8283592134319229004,14057209702685355942", "cites_id": ["8283592134319229004", "14057209702685355942"]}, "2hA4X9wAAAAJ:vDijr-p_gm4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Open-Vocabulary SAM3D: Towards Training-free Open-Vocabulary 3D Scene Understanding", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:vDijr-p_gm4C", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7088044729516783237,9858564583378160570", "cites_id": ["7088044729516783237", "9858564583378160570"]}, "2hA4X9wAAAAJ:URolC5Kub84C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ID-Sculpt: ID-aware 3D Head Generation from Single In-the-wild Portrait Image", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:URolC5Kub84C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1097208499637414941", "cites_id": ["1097208499637414941"]}, "2hA4X9wAAAAJ:p__nRnzSRKYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real-IAD D3: A Real-World 2D/Pseudo-3D/3D Dataset for Industrial Anomaly Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:p__nRnzSRKYC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16820217880168811783", "cites_id": ["16820217880168811783"]}, "2hA4X9wAAAAJ:9Nmd_mFXekcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring real&synthetic dataset and linear attention in image restoration", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:9Nmd_mFXekcC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16466214268251403247,4061953943950438069", "cites_id": ["16466214268251403247", "4061953943950438069"]}, "2hA4X9wAAAAJ:XD-gHx7UXLsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dynamiccontrol: Adaptive condition selection for improved text-to-image generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:XD-gHx7UXLsC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16323182256059246414", "cites_id": ["16323182256059246414"]}, "2hA4X9wAAAAJ:fQNAKQ3IYiAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dual path transformer with partition attention", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:fQNAKQ3IYiAC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4038637268408891031", "cites_id": ["4038637268408891031"]}, "2hA4X9wAAAAJ:0N-VGjzr574C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Imit diff: Semantics guided diffusion transformer with dual resolution fusion for imitation learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:0N-VGjzr574C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14765411498905513057", "cites_id": ["14765411498905513057"]}, "2hA4X9wAAAAJ:AvfA0Oy_GE0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Decouple and track: Benchmarking and improving video diffusion transformers for motion transfer", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:AvfA0Oy_GE0C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2868625499116191367", "cites_id": ["2868625499116191367"]}, "2hA4X9wAAAAJ:BwyfMAYsbu0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal Industrial Anomaly Detection via Hybrid Fusion. In 2023 IEEE", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:BwyfMAYsbu0C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14171877871974042276", "cites_id": ["14171877871974042276"]}, "2hA4X9wAAAAJ:nrtMV_XWKgEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EMOv2: Pushing 5 M Vision Model Frontier", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:nrtMV_XWKgEC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15262123136209008253", "cites_id": ["15262123136209008253"]}, "2hA4X9wAAAAJ:oNZyr7d5Mn4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented Efficient Long Video Understanding. arXiv preprint arXiv (2025)", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:oNZyr7d5Mn4C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3976279409743849232", "cites_id": ["3976279409743849232"]}, "2hA4X9wAAAAJ:KUbvn5osdkgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CustAny: Customizing Anything from A Single Example", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:KUbvn5osdkgC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14815150302990230196", "cites_id": ["14815150302990230196"]}, "2hA4X9wAAAAJ:yB1At4FlUx8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SVFR: A Unified Framework for Generalized Video Face Restoration", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:yB1At4FlUx8C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=293601137411401292", "cites_id": ["293601137411401292"]}, "2hA4X9wAAAAJ:k8Z6L05lTy4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diad: A diffusion-based framework for multi-class anomaly detection. 2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:k8Z6L05lTy4C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=166655263677490247", "cites_id": ["166655263677490247"]}, "2hA4X9wAAAAJ:HbR8gkJAVGIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "IVEBench: Modern Benchmark Suite for Instruction-Guided Video Editing Assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:HbR8gkJAVGIC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13304477295203947619", "cites_id": ["13304477295203947619"]}, "2hA4X9wAAAAJ:-FonjvnnhkoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Identity-preserving text-to-video generation guided by simple yet effective spatial-temporal decoupled representations", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:-FonjvnnhkoC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17850277013720886624", "cites_id": ["17850277013720886624"]}, "2hA4X9wAAAAJ:VaXvl8Fpj5cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HV-MMBench: Benchmarking MLLMs for Human-Centric Video Understanding", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:VaXvl8Fpj5cC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10936561974460781463", "cites_id": ["10936561974460781463"]}, "2hA4X9wAAAAJ:tYavs44e6CUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VTBench: Comprehensive Benchmark Suite Towards Real-World Virtual Try-on Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tYavs44e6CUC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15009237061491151589", "cites_id": ["15009237061491151589"]}, "2hA4X9wAAAAJ:ILKRHgRFtOwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Align and Surpass Human Camouflaged Perception: Visual Refocus Reinforcement Fine-Tuning", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ILKRHgRFtOwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9862880295627317280", "cites_id": ["9862880295627317280"]}, "2hA4X9wAAAAJ:4MWp96NkSFoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Swin DiT: Diffusion Transformer using Pseudo Shifted Windows", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:4MWp96NkSFoC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4726913908055760299", "cites_id": ["4726913908055760299"]}, "2hA4X9wAAAAJ:vbGhcppDl1QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Semi-Cervixseg: A Multi-Stage Training Strategy for Semi-Supervised Cervical Segmentation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:vbGhcppDl1QC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17370506442416182114", "cites_id": ["17370506442416182114"]}, "2hA4X9wAAAAJ:WA5NYHcadZ8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "StyleMaster: Towards Flexible Stylized Image Generation with Diffusion Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:WA5NYHcadZ8C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14856364155831484346", "cites_id": ["14856364155831484346"]}, "2hA4X9wAAAAJ:kRWSkSYxWN8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DiffFAE: Advancing high-fidelity one-shot facial appearance editing with space-sensitive customization and semantic preservation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:kRWSkSYxWN8C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3191591483822274504", "cites_id": ["3191591483822274504"]}, "2hA4X9wAAAAJ:VOx2b1Wkg3QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SelFSR: Self-Conditioned Face Super-Resolution in the Wild via Flow Field Degradation Network", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:VOx2b1Wkg3QC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17179573250384675307", "cites_id": ["17179573250384675307"]}, "2hA4X9wAAAAJ:uJ-U7cs_P_0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Knowledge rearranged multi-teacher distillation"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:uJ-U7cs_P_0C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6337522376339601072", "cites_id": ["6337522376339601072"]}, "2hA4X9wAAAAJ:hCrLmN-GePgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ShortcutBreaker: Low-Rank Noisy Bottleneck with Global Perturbation Attention for Multi-Class Unsupervised Anomaly Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:hCrLmN-GePgC", "num_citations": 0}, "2hA4X9wAAAAJ:ClCfbGk0d_YC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TokenAR: Multiple Subject Generation via Autoregressive Token-level enhancement", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ClCfbGk0d_YC", "num_citations": 0}, "2hA4X9wAAAAJ:xtoqd-5pKcoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LLM-Oriented Token-Adaptive Knowledge Distillation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:xtoqd-5pKcoC", "num_citations": 0}, "2hA4X9wAAAAJ:edDO8Oi4QzsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ImitDiff: Transferring Foundation-Model Priors for Distraction-Robust Visuomotor Policy", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:edDO8Oi4QzsC", "num_citations": 0}, "2hA4X9wAAAAJ:Ug5p-4gJ2f0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Human-MME: A Holistic Evaluation Benchmark for Human-Centric Multimodal Large Language Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:Ug5p-4gJ2f0C", "num_citations": 0}, "2hA4X9wAAAAJ:foquWX3nUaYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual Multi-Agent System: Mitigating Hallucination Snowballing via Visual Flow", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:foquWX3nUaYC", "num_citations": 0}, "2hA4X9wAAAAJ:ruyezt5ZtCIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EfficientIML: Efficient High-Resolution Image Manipulation Localization", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ruyezt5ZtCIC", "num_citations": 0}, "2hA4X9wAAAAJ:XoXfffV-tXoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Explore Inversion and Invariance in Flow Transformer for General Conditional Generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:XoXfffV-tXoC", "num_citations": 0}, "2hA4X9wAAAAJ:i2xiXl-TujoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:i2xiXl-TujoC", "num_citations": 0}, "2hA4X9wAAAAJ:SpbeaW3--B0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "StrandDesigner: Towards Practical Strand Generation with Sketch Guidance", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:SpbeaW3--B0C", "num_citations": 0}, "2hA4X9wAAAAJ:Dip1O2bNi0gC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HumanVideo-MME: Benchmarking MLLMs for Human-Centric Video Understanding", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:Dip1O2bNi0gC", "num_citations": 0}, "2hA4X9wAAAAJ:LI9QrySNdTsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Semantic Frame Interpolation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:LI9QrySNdTsC", "num_citations": 0}, "2hA4X9wAAAAJ:WZBGuue-350C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:WZBGuue-350C", "num_citations": 0}, "2hA4X9wAAAAJ:PoWvk5oyLR8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Explainable Bilingual Multimodal Misinformation Detection and Localization", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:PoWvk5oyLR8C", "num_citations": 0}, "2hA4X9wAAAAJ:MLfJN-KU85MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Omni-AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented for Efficient Long Video Understanding", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:MLfJN-KU85MC", "num_citations": 0}, "2hA4X9wAAAAJ:gsN89kCJA0AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:gsN89kCJA0AC", "num_citations": 0}, "2hA4X9wAAAAJ:ML0RJ9NH7IQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MagicFace: Slot-Driven High-Fidelity One-Shot Facial Appearance Editing", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ML0RJ9NH7IQC", "num_citations": 0}, "2hA4X9wAAAAJ:epqYDVWIO7EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Image Inversion: A Survey from GANs to Diffusion and Beyond", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:epqYDVWIO7EC", "num_citations": 0}, "2hA4X9wAAAAJ:S16KYo8Pm5AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:S16KYo8Pm5AC", "num_citations": 0}, "2hA4X9wAAAAJ:hMsQuOkrut0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GroundingFace: Fine-grained Face Understanding via Pixel Grounding Multimodal Large Language Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:hMsQuOkrut0C", "num_citations": 0}, "2hA4X9wAAAAJ:hkOj_22Ku90C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:hkOj_22Ku90C", "num_citations": 0}, "2hA4X9wAAAAJ:PR6Y55bgFSsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Temporal and Interactive Modeling for Efficient Human-Human Motion Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:PR6Y55bgFSsC", "num_citations": 0}, "2hA4X9wAAAAJ:kz9GbA2Ns4gC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ArtWeaver: Advanced Dynamic Style Integration via Diffusion Model", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:kz9GbA2Ns4gC", "num_citations": 0}}, "citedby5y": 4674, "hindex": 34, "hindex5y": 34, "i10index": 78, "i10index5y": 78, "cites_per_year": {"2020": 20, "2021": 83, "2022": 153, "2023": 402, "2024": 1279, "2025": 2708}, "updated": "2025-10-31 08:27:26.984106"}