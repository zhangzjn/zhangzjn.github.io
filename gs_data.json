{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "2hA4X9wAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Jiangning Zhang (张江宁)", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=2hA4X9wAAAAJ&citpid=3", "affiliation": "Youtu Lab, Tencent | Zhejiang University", "organization": 1118375729466322660, "interests": ["Embodied AI | FM"], "email_domain": "@zju.edu.cn", "homepage": "https://zhangzjn.github.io/", "citedby": 6018, "publications": {"2hA4X9wAAAAJ:uWQEDVKXjbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rethinking mobile block for efficient attention-based models", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:uWQEDVKXjbEC", "num_citations": 374, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8399801815353872086,6803692528838506853,4462447219040254297", "cites_id": ["8399801815353872086", "6803692528838506853", "4462447219040254297"]}, "2hA4X9wAAAAJ:UxriW0iASnsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Omni-frequency channel-selection representations for unsupervised anomaly detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:UxriW0iASnsC", "num_citations": 279, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15876710250266998666", "cites_id": ["15876710250266998666"]}, "2hA4X9wAAAAJ:eJXPG6dFmWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Diffusion-Based Framework for Multi-Class Anomaly Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:eJXPG6dFmWUC", "num_citations": 273, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4516755124680140750,166655263677490247", "cites_id": ["4516755124680140750", "166655263677490247"]}, "2hA4X9wAAAAJ:ldfaerwXgEUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards open vocabulary learning: A survey", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ldfaerwXgEUC", "num_citations": 270, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4374069864889678520", "cites_id": ["4374069864889678520"]}, "2hA4X9wAAAAJ:SP6oXDckpogC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal industrial anomaly detection via hybrid fusion", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:SP6oXDckpogC", "num_citations": 268, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8940602570027713712,2540830192280547690", "cites_id": ["8940602570027713712", "2540830192280547690"]}, "2hA4X9wAAAAJ:XiSMed-E-HIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning by analogy: Reliable supervision from transformations for unsupervised optical flow estimation", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:XiSMed-E-HIC", "num_citations": 238, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3875015729190234590", "cites_id": ["3875015729190234590"]}, "2hA4X9wAAAAJ:BqipwSGYUEgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "APRIL-GAN: A Zero-/Few-Shot Anomaly Classification and Segmentation Method", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:BqipwSGYUEgC", "num_citations": 221, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1984569996728884691,1670056311724797007", "cites_id": ["1984569996728884691", "1670056311724797007"]}, "2hA4X9wAAAAJ:mvPsJ3kp5DgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Anomalydiffusion: Few-shot anomaly image generation with diffusion model", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:mvPsJ3kp5DgC", "num_citations": 189, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15920211044737566150", "cites_id": ["15920211044737566150"]}, "2hA4X9wAAAAJ:p2g8aNsByqUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Freenet: Multi-identity face reenactment", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:p2g8aNsByqUC", "num_citations": 189, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11676370670744214493,14143495475025615130", "cites_id": ["11676370670744214493", "14143495475025615130"]}, "2hA4X9wAAAAJ:t7zJ5fGR-2UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Point cloud mamba: Point cloud learning via state space model", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:t7zJ5fGR-2UC", "num_citations": 183, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11650303125677654154", "cites_id": ["11650303125677654154"]}, "2hA4X9wAAAAJ:UHK10RUVsp4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mambaad: Exploring state space models for multi-class unsupervised anomaly detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:UHK10RUVsp4C", "num_citations": 182, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15481876724486702892", "cites_id": ["15481876724486702892"]}, "2hA4X9wAAAAJ:_Re3VWB3Y0AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaclip: Adapting clip with hybrid learnable prompts for zero-shot anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:_Re3VWB3Y0AC", "num_citations": 180, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14822412996516810335", "cites_id": ["14822412996516810335"]}, "2hA4X9wAAAAJ:q3oQSFYPqjQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real-IAD: A Real-World Multi-View Dataset for Benchmarking Versatile Industrial Anomaly Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:q3oQSFYPqjQC", "num_citations": 166, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5525112057645376510", "cites_id": ["5525112057645376510"]}, "2hA4X9wAAAAJ:V3AGJWp-ZtQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deepfake Generation and Detection: A Benchmark and Survey", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:V3AGJWp-ZtQC", "num_citations": 142, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9827397824432092836", "cites_id": ["9827397824432092836"]}, "2hA4X9wAAAAJ:ZfRJV9d4-WMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Clip-ad: A language-guided staged dual-path model for zero-shot anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ZfRJV9d4-WMC", "num_citations": 109, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8002141840995702613", "cites_id": ["8002141840995702613"]}, "2hA4X9wAAAAJ:CHSYGLWDkRkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A survey on visual anomaly detection: Challenge, approach, and prospect", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:CHSYGLWDkRkC", "num_citations": 101, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15683395947501387504", "cites_id": ["15683395947501387504"]}, "2hA4X9wAAAAJ:WbkHhVStYXYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Region-aware face swapping", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:WbkHhVStYXYC", "num_citations": 99, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12630937752246463171", "cites_id": ["12630937752246463171"]}, "2hA4X9wAAAAJ:zA6iFVUQeVQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Remembering Normality: Memory-guided Knowledge Distillation for Unsupervised Anomaly Detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:zA6iFVUQeVQC", "num_citations": 93, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6873568589231201245", "cites_id": ["6873568589231201245"]}, "2hA4X9wAAAAJ:f2IySw72cVMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring plain vit reconstruction for multi-class unsupervised anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:f2IySw72cVMC", "num_citations": 87, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1180170355200597287,1075116936351398361", "cites_id": ["1180170355200597287", "1075116936351398361"]}, "2hA4X9wAAAAJ:dTyEYWd-f8wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MotionBooth: Motion-Aware Customized Text-to-Video Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:dTyEYWd-f8wC", "num_citations": 83, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5217561798098030587", "cites_id": ["5217561798098030587"]}, "2hA4X9wAAAAJ:D03iK_w7-QYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PortraitBooth: A Versatile Portrait Model for Fast Identity-preserved Personalization", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:D03iK_w7-QYC", "num_citations": 76, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2807970536527593463", "cites_id": ["2807970536527593463"]}, "2hA4X9wAAAAJ:fEOibwPWpKIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Face-Adapter for Pre-trained Diffusion Models with Fine-Grained ID and Attribute Control", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:fEOibwPWpKIC", "num_citations": 70, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17368182402162268103", "cites_id": ["17368182402162268103"]}, "2hA4X9wAAAAJ:VLnqNzywnoUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mobilemamba: Lightweight multi-receptive visual mamba network", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:VLnqNzywnoUC", "num_citations": 67, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9415738422234865861", "cites_id": ["9415738422234865861"]}, "2hA4X9wAAAAJ:ZHo1McVdvXMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sfnet: Faster and Accurate Semantic Segmentation Via Semantic Flow", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ZHo1McVdvXMC", "num_citations": 65, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=423028739487429125", "cites_id": ["423028739487429125"]}, "2hA4X9wAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Designing One Unified Framework for High-Fidelity Face Reenactment and Swapping", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:9ZlFYXVOiuMC", "num_citations": 63, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10517210380745041646", "cites_id": ["10517210380745041646"]}, "2hA4X9wAAAAJ:tOudhMTPpwUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mixteacher: Mining promising labels with mixed scale teacher for semi-supervised object detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tOudhMTPpwUC", "num_citations": 62, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=360005364412013411", "cites_id": ["360005364412013411"]}, "2hA4X9wAAAAJ:k_IJM867U9cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "High-fidelity Generalized Emotional Talking Face Generation with Multi-modal Emotion Space Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:k_IJM867U9cC", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14284243388686741119", "cites_id": ["14284243388686741119"]}, "2hA4X9wAAAAJ:RGFaLdJalmkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dtvnet: Dynamic time-lapse video generation via single still image", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:RGFaLdJalmkC", "num_citations": 59, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8543456608729588740,12995822360434038988", "cites_id": ["8543456608729588740", "12995822360434038988"]}, "2hA4X9wAAAAJ:z_wVstp3MssC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sonic: Shifting focus to global audio perception in portrait animation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:z_wVstp3MssC", "num_citations": 57, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15991424711205920935", "cites_id": ["15991424711205920935"]}, "2hA4X9wAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Eatformer: Improving vision transformer inspired by evolutionary algorithm", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:qxL8FJ1GzNcC", "num_citations": 53, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14151647974405698917", "cites_id": ["14151647974405698917"]}, "2hA4X9wAAAAJ:GnPB-g6toBAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RFNet: recurrent forward network for dense point cloud completion", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:GnPB-g6toBAC", "num_citations": 51, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1369368557383473552", "cites_id": ["1369368557383473552"]}, "2hA4X9wAAAAJ:Tiz5es2fbqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Realistic face reenactment via self-supervised disentangling of identity and pose", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:Tiz5es2fbqcC", "num_citations": 51, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2172292118953588179", "cites_id": ["2172292118953588179"]}, "2hA4X9wAAAAJ:-_dYPAW6P2MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-supervised feature adaptation for 3d industrial anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:-_dYPAW6P2MC", "num_citations": 46, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11021572587767727927", "cites_id": ["11021572587767727927"]}, "2hA4X9wAAAAJ:tzM49s52ZIMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Freemotion: A unified framework for number-free text-to-motion synthesis", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tzM49s52ZIMC", "num_citations": 46, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4441956630149334493", "cites_id": ["4441956630149334493"]}, "2hA4X9wAAAAJ:D_sINldO8mEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rethinking Reverse Distillation for Multi-Modal Anomaly Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:D_sINldO8mEC", "num_citations": 45, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8372764793963584341", "cites_id": ["8372764793963584341"]}, "2hA4X9wAAAAJ:kzcrU_BdoSEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GPT-4V-AD: Exploring Grounding Potential of VQA-Oriented GPT-4V for Zero-Shot Anomaly Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:kzcrU_BdoSEC", "num_citations": 41, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8528002381465121274", "cites_id": ["8528002381465121274"]}, "2hA4X9wAAAAJ:b0M2c_1WBrUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards language-driven video inpainting via multimodal large language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:b0M2c_1WBrUC", "num_citations": 40, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8854937429748086141", "cites_id": ["8854937429748086141"]}, "2hA4X9wAAAAJ:XiVPGOgt02cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MotionMaster: Training-free Camera Motion Transfer For Video Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:XiVPGOgt02cC", "num_citations": 39, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12403200263986038711,16826424060222634744", "cites_id": ["12403200263986038711", "16826424060222634744"]}, "2hA4X9wAAAAJ:RYcK_YlVTxYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning-based hand motion capture and understanding in assembly process", "pub_year": "2018"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:RYcK_YlVTxYC", "num_citations": 37, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17957912339505702803", "cites_id": ["17957912339505702803"]}, "2hA4X9wAAAAJ:t6usbXjVLHcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Pointrwkv: Efficient rwkv-like model for hierarchical point cloud learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:t6usbXjVLHcC", "num_citations": 36, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11075235487468564374", "cites_id": ["11075235487468564374"]}, "2hA4X9wAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning with Noisy labels via Self-supervised Adversarial Noisy Masking", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:e5wmG9Sq2KIC", "num_citations": 35, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14616143760826087984", "cites_id": ["14616143760826087984"]}, "2hA4X9wAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "3QNet: 3D Point Cloud Geometry Quantization Compression Network", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ZeXyd9-uunAC", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10354066383229872446", "cites_id": ["10354066383229872446"]}, "2hA4X9wAAAAJ:vRqMK49ujn8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Iterative few-shot semantic segmentation from image label text", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:vRqMK49ujn8C", "num_citations": 33, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7445612649408352675", "cites_id": ["7445612649408352675"]}, "2hA4X9wAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multilevel Spatial-Temporal Feature Aggregation for Video Object Detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:4TOpqqG69KYC", "num_citations": 33, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=915144743605869208", "cites_id": ["915144743605869208"]}, "2hA4X9wAAAAJ:JQOojiI6XY0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Llava-kd: A framework of distilling multimodal large language models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:JQOojiI6XY0C", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14451749426526516059", "cites_id": ["14451749426526516059"]}, "2hA4X9wAAAAJ:NJ774b8OgUMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fitdit: Advancing the authentic garment details for high-fidelity virtual try-on", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:NJ774b8OgUMC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11863285159648257198", "cites_id": ["11863285159648257198"]}, "2hA4X9wAAAAJ:nb7KW1ujOQ8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Reference twice: A simple and unified baseline for few-shot instance segmentation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:nb7KW1ujOQ8C", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5798636040124543876", "cites_id": ["5798636040124543876"]}, "2hA4X9wAAAAJ:AXPGKjj_ei8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vividpose: Advancing stable video diffusion for realistic human image animation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:AXPGKjj_ei8C", "num_citations": 30, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6016083296626963487", "cites_id": ["6016083296626963487"]}, "2hA4X9wAAAAJ:tKAzc9rXhukC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A comprehensive library for benchmarking multi-class visual anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tKAzc9rXhukC", "num_citations": 29, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3639034251259405294,7329494456372286830", "cites_id": ["3639034251259405294", "7329494456372286830"]}, "2hA4X9wAAAAJ:eMMeJKvmdy0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M3dm-nr: Rgb-3d noisy-resistant industrial anomaly detection via multimodal denoising", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:eMMeJKvmdy0C", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18111798115065979809", "cites_id": ["18111798115065979809"]}, "2hA4X9wAAAAJ:uc_IGeMz5qoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rwkv-unet: Improving unet with long-range cooperation for effective medical image segmentation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:uc_IGeMz5qoC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5687313393756329486", "cites_id": ["5687313393756329486"]}, "2hA4X9wAAAAJ:bnK-pcrLprsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning feature inversion for multi-class anomaly detection under general-purpose coco-ad benchmark", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:bnK-pcrLprsC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17322629230626563646", "cites_id": ["17322629230626563646"]}, "2hA4X9wAAAAJ:rO6llkc54NcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:rO6llkc54NcC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2137844415567478150", "cites_id": ["2137844415567478150"]}, "2hA4X9wAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Analogous to evolutionary algorithm: Designing a unified sequence model", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:kNdYIx-mwKoC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12574250028327747897", "cites_id": ["12574250028327747897"]}, "2hA4X9wAAAAJ:dQ2og3OwTAUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Osv: One step is enough for high-quality image to video generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:dQ2og3OwTAUC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17727228944916732684", "cites_id": ["17727228944916732684"]}, "2hA4X9wAAAAJ:j8SEvjWlNXcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unveil inversion and invariance in flow transformer for versatile image editing", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:j8SEvjWlNXcC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=819932006508377753", "cites_id": ["819932006508377753"]}, "2hA4X9wAAAAJ:g5m5HwL7SMYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PVG: Progressive Vision Graph for Vision Recognition", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:g5m5HwL7SMYC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17736928290896075046", "cites_id": ["17736928290896075046"]}, "2hA4X9wAAAAJ:tuHXwOkdijsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UltraVideo: High-Quality UHD Video Dataset with Comprehensive Captions", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tuHXwOkdijsC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8830646779127013911", "cites_id": ["8830646779127013911"]}, "2hA4X9wAAAAJ:5ugPr518TE4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SuperSVG: Superpixel-based scalable vector graphics synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:5ugPr518TE4C", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16395703982419708695", "cites_id": ["16395703982419708695"]}, "2hA4X9wAAAAJ:lSLTfruPkqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Calibrated Teacher for Sparsely Annotated Object Detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:lSLTfruPkqcC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9299468912113782427", "cites_id": ["9299468912113782427"]}, "2hA4X9wAAAAJ:fPk4N6BV_jEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Better\" CMOS\" Produces Clearer Images: Learning Space-Variant Blur Estimation for Blind Image Super-Resolution", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:fPk4N6BV_jEC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3682948729479689165,14923800501068358589", "cites_id": ["3682948729479689165", "14923800501068358589"]}, "2hA4X9wAAAAJ:5Ul4iDaHHb8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Explore in-context segmentation via latent diffusion models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:5Ul4iDaHHb8C", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11945616096981116533", "cites_id": ["11945616096981116533"]}, "2hA4X9wAAAAJ:08ZZubdj9fEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal-driven talking face generation via a unified diffusion-based generator", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:08ZZubdj9fEC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10621497816434551698", "cites_id": ["10621497816434551698"]}, "2hA4X9wAAAAJ:tS2w5q8j5-wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Scsnet: An efficient paradigm for learning simultaneously image colorization and super-resolution", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tS2w5q8j5-wC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10250034740894351500", "cites_id": ["10250034740894351500"]}, "2hA4X9wAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adding before pruning: Sparse filter fusion for deep convolutional neural networks via auxiliary attention", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:7PzlFSSx8tAC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11443840263675098986", "cites_id": ["11443840263675098986"]}, "2hA4X9wAAAAJ:bFI3QPDXJZMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Generalist FaceX via Learning Unified Facial Representation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:bFI3QPDXJZMC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1518916058955134215", "cites_id": ["1518916058955134215"]}, "2hA4X9wAAAAJ:e_rmSamDkqQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual document understanding and question answering: A multi-agent collaboration framework with test-time scaling", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:e_rmSamDkqQC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=970663921266525040", "cites_id": ["970663921266525040"]}, "2hA4X9wAAAAJ:2KloaMYe4IUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DiffuMatting: Synthesizing Arbitrary Objects with Matting-level Annotation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:2KloaMYe4IUC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7118312767467766590", "cites_id": ["7118312767467766590"]}, "2hA4X9wAAAAJ:xtRiw3GOFMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with Fine-Grained Feature Representation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:xtRiw3GOFMkC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12669725982803146844", "cites_id": ["12669725982803146844"]}, "2hA4X9wAAAAJ:N5tVd3kTz84C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MambaGesture: Enhancing Co-Speech Gesture Generation with Mamba and Disentangled Multi-Modality Fusion", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:N5tVd3kTz84C", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2611012089890276440", "cites_id": ["2611012089890276440"]}, "2hA4X9wAAAAJ:geHnlv5EZngC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dual-path Frequency Discriminators for Few-shot Anomaly Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:geHnlv5EZngC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8853579622716673300", "cites_id": ["8853579622716673300"]}, "2hA4X9wAAAAJ:K3LRdlH-MEoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Apb2face: Audio-guided face reenactment with auxiliary pose and blink signals", "pub_year": "2020"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:K3LRdlH-MEoC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17109399904647244610", "cites_id": ["17109399904647244610"]}, "2hA4X9wAAAAJ:LjlpjdlvIbIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Licrocc: Teach radar for accurate semantic occupancy prediction using lidar and camera", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:LjlpjdlvIbIC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13527183636746229220", "cites_id": ["13527183636746229220"]}, "2hA4X9wAAAAJ:eflP2zaiRacC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dmad: Dual memory bank for real-world anomaly detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:eflP2zaiRacC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8989284569078344959", "cites_id": ["8989284569078344959"]}, "2hA4X9wAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning To Measure the Point Cloud Reconstruction Loss in a Representation Space", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:hMod-77fHWUC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8828344287570774351,3635818321333649508", "cites_id": ["8828344287570774351", "3635818321333649508"]}, "2hA4X9wAAAAJ:738O_yMBCRsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real-time audio-guided multi-face reenactment", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:738O_yMBCRsC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10955743015947891050,18434141885400621884", "cites_id": ["10955743015947891050", "18434141885400621884"]}, "2hA4X9wAAAAJ:J-pR_7NvFogC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-supervised likelihood estimation with energy guidance for anomaly segmentation in urban scenes", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:J-pR_7NvFogC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3871129052633933760", "cites_id": ["3871129052633933760"]}, "2hA4X9wAAAAJ:1qzjygNMrQYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TransAVS: End-to-End Audio-Visual Segmentation with Transformer", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:1qzjygNMrQYC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4232256084207778991,11454923689554224673", "cites_id": ["4232256084207778991", "11454923689554224673"]}, "2hA4X9wAAAAJ:3s1wT3WcHBgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Toward High Quality Facial Representation Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:3s1wT3WcHBgC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16502864466572204955", "cites_id": ["16502864466572204955"]}, "2hA4X9wAAAAJ:blknAaTinKkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Global-aware Kernel for Image Harmonization", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:blknAaTinKkC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4311617877515083361", "cites_id": ["4311617877515083361"]}, "2hA4X9wAAAAJ:P5F9QuxV20EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MMoFusion: Multi-modal co-speech motion generation with diffusion model", "pub_year": "2026"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:P5F9QuxV20EC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4716720128736518523", "cites_id": ["4716720128736518523"]}, "2hA4X9wAAAAJ:35r97b3x0nAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TexDreamer: Towards Zero-Shot High-Fidelity 3D Human Texture Generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:35r97b3x0nAC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10346512206618482675", "cites_id": ["10346512206618482675"]}, "2hA4X9wAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaptive Recurrent Forward Network for Dense Point Cloud Completion", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:mVmsd5A6BfQC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11440181636670610641", "cites_id": ["11440181636670610641"]}, "2hA4X9wAAAAJ:EkHepimYqZsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Realtalk: Real-time and realistic audio-driven face generation with 3d facial prior-guided identity alignment network", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:EkHepimYqZsC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6659931522436241189", "cites_id": ["6659931522436241189"]}, "2hA4X9wAAAAJ:Fu2w8maKXqMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fetch and Forge: Efficient Dataset Condensation for Object Detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:Fu2w8maKXqMC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7994250064571555197", "cites_id": ["7994250064571555197"]}, "2hA4X9wAAAAJ:p__nRnzSRKYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real-iad d3: A real-world 2d/pseudo-3d/3d dataset for industrial anomaly detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:p__nRnzSRKYC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16820217880168811783", "cites_id": ["16820217880168811783"]}, "2hA4X9wAAAAJ:BUYA1_V_uYcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "High-efficient diffusion model fine-tuning with progressive sparse low-rank adaptation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:BUYA1_V_uYcC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3702346010126314147,11396892856444237848", "cites_id": ["3702346010126314147", "11396892856444237848"]}, "2hA4X9wAAAAJ:ZuybSZzF8UAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MDT-A2G: Exploring Masked Diffusion Transformers for Co-Speech Gesture Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ZuybSZzF8UAC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5415177780427279430", "cites_id": ["5415177780427279430"]}, "2hA4X9wAAAAJ:g3aElNc5_aQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Timotion: Temporal and interactive framework for efficient human-human motion generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:g3aElNc5_aQC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11937808497014036628", "cites_id": ["11937808497014036628"]}, "2hA4X9wAAAAJ:ipzZ9siozwsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Are they the same? exploring visual correspondence shortcomings of multimodal llms", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ipzZ9siozwsC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9461818450777280555", "cites_id": ["9461818450777280555"]}, "2hA4X9wAAAAJ:LPZeul_q3PIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Pointseg: A training-free paradigm for 3d scene segmentation via foundation models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:LPZeul_q3PIC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15837125486049142370", "cites_id": ["15837125486049142370"]}, "2hA4X9wAAAAJ:WqliGbK-hY8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Multi-view Anomaly Detection with Efficient Adaptive Selection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:WqliGbK-hY8C", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13828431456489722537", "cites_id": ["13828431456489722537"]}, "2hA4X9wAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fast Point Cloud Sampling Network", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:L8Ckcad2t8MC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8849514971316997554", "cites_id": ["8849514971316997554"]}, "2hA4X9wAAAAJ:oNZyr7d5Mn4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adavideorag: Omni-contextual adaptive retrieval-augmented efficient long video understanding", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:oNZyr7d5Mn4C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8282982161654942989,12783168082894237921", "cites_id": ["8282982161654942989", "12783168082894237921"]}, "2hA4X9wAAAAJ:TIZ-Mc8IlK0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "So-fake: Benchmarking and explaining social media image forgery detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:TIZ-Mc8IlK0C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16026523829622046068", "cites_id": ["16026523829622046068"]}, "2hA4X9wAAAAJ:AvfA0Oy_GE0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Decouple and track: Benchmarking and improving video diffusion transformers for motion transfer", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:AvfA0Oy_GE0C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2868625499116191367", "cites_id": ["2868625499116191367"]}, "2hA4X9wAAAAJ:PR6Y55bgFSsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Temporal and interactive modeling for efficient human-human motion generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:PR6Y55bgFSsC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=929060197698606779", "cites_id": ["929060197698606779"]}, "2hA4X9wAAAAJ:rmuvC79q63oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vismem: Latent vision memory unlocks potential of vision-language models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:rmuvC79q63oC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9727316877683377454", "cites_id": ["9727316877683377454"]}, "2hA4X9wAAAAJ:5qfkUJPXOUwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UltraGen: High-Resolution Video Generation with Hierarchical Attention", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:5qfkUJPXOUwC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15103343668966136317,1020856985361944956", "cites_id": ["15103343668966136317", "1020856985361944956"]}, "2hA4X9wAAAAJ:0KyAp5RtaNEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Improving autoregressive visual generation with cluster-oriented token prediction", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:0KyAp5RtaNEC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=917972641444598901", "cites_id": ["917972641444598901"]}, "2hA4X9wAAAAJ:_Ybze24A_UAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Textual decomposition then sub-motion-space scattering for open-vocabulary motion generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:_Ybze24A_UAC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8283592134319229004,14057209702685355942", "cites_id": ["8283592134319229004", "14057209702685355942"]}, "2hA4X9wAAAAJ:uLbwQdceFCQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Llava-vsd: Large language-and-vision assistant for visual spatial description", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:uLbwQdceFCQC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11755256025716233943", "cites_id": ["11755256025716233943"]}, "2hA4X9wAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Resolution-Free Point Cloud Sampling Network with Data Distillation", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:dhFuZR0502QC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9525132096843510227", "cites_id": ["9525132096843510227"]}, "2hA4X9wAAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning to Train a Point Cloud Reconstruction Network Without Matching", "pub_year": "2022"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:QIV2ME_5wuYC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14413331854945255272", "cites_id": ["14413331854945255272"]}, "2hA4X9wAAAAJ:HbR8gkJAVGIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ivebench: Modern benchmark suite for instruction-guided video editing assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:HbR8gkJAVGIC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13304477295203947619", "cites_id": ["13304477295203947619"]}, "2hA4X9wAAAAJ:URolC5Kub84C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Id-Sculpt: Id-aware 3D head generation from single in-the-wild portrait image", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:URolC5Kub84C", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1097208499637414941", "cites_id": ["1097208499637414941"]}, "2hA4X9wAAAAJ:tkaPQYYpVKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Anymaker: Zero-shot general object customization via decoupled dual-level id injection", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tkaPQYYpVKoC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1234404490701404384", "cites_id": ["1234404490701404384"]}, "2hA4X9wAAAAJ:sSrBHYA8nusC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning hierarchical and efficient Person re-identification for robotic navigation", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:sSrBHYA8nusC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4962563113221040921,15631123984536072886", "cites_id": ["4962563113221040921", "15631123984536072886"]}, "2hA4X9wAAAAJ:edDO8Oi4QzsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ImitDiff: Transferring Foundation-Model Priors for Distraction-Robust Visuomotor Policy", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:edDO8Oi4QzsC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14765411498905513057,837463604332132162", "cites_id": ["14765411498905513057", "837463604332132162"]}, "2hA4X9wAAAAJ:XD-gHx7UXLsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dynamiccontrol: Adaptive condition selection for improved text-to-image generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:XD-gHx7UXLsC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16323182256059246414", "cites_id": ["16323182256059246414"]}, "2hA4X9wAAAAJ:vDijr-p_gm4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Open-Vocabulary SAM3D: Towards Training-free Open-Vocabulary 3D Scene Understanding", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:vDijr-p_gm4C", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9858564583378160570", "cites_id": ["9858564583378160570"]}, "2hA4X9wAAAAJ:GtLg2Ama23sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:GtLg2Ama23sC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7429853689874516794", "cites_id": ["7429853689874516794"]}, "2hA4X9wAAAAJ:foquWX3nUaYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual multi-agent system: Mitigating hallucination snowballing via visual flow", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:foquWX3nUaYC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=529317566516561154", "cites_id": ["529317566516561154"]}, "2hA4X9wAAAAJ:nrtMV_XWKgEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Emov2: Pushing 5 m vision model frontier", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:nrtMV_XWKgEC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14745835681839775305", "cites_id": ["14745835681839775305"]}, "2hA4X9wAAAAJ:yB1At4FlUx8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Svfr: A unified framework for generalized video face restoration", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:yB1At4FlUx8C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=293601137411401292", "cites_id": ["293601137411401292"]}, "2hA4X9wAAAAJ:9Nmd_mFXekcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring real&synthetic dataset and linear attention in image restoration", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:9Nmd_mFXekcC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16466214268251403247,4061953943950438069", "cites_id": ["16466214268251403247", "4061953943950438069"]}, "2hA4X9wAAAAJ:fQNAKQ3IYiAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dual path transformer with partition attention", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:fQNAKQ3IYiAC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4038637268408891031", "cites_id": ["4038637268408891031"]}, "2hA4X9wAAAAJ:kh2fBNsKQNwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dip: Taming diffusion models in pixel space", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:kh2fBNsKQNwC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14110845429114433089", "cites_id": ["14110845429114433089"]}, "2hA4X9wAAAAJ:PVjk1bu6vJQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards One-step Causal Video Generation via Adversarial Self-Distillation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:PVjk1bu6vJQC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3572895901529330287", "cites_id": ["3572895901529330287"]}, "2hA4X9wAAAAJ:vbGhcppDl1QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Semi-Cervixseg: A multi-stage training strategy for semi-supervised cervical segmentation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:vbGhcppDl1QC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17370506442416182114", "cites_id": ["17370506442416182114"]}, "2hA4X9wAAAAJ:KUbvn5osdkgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Custany: Customizing anything from a single example", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:KUbvn5osdkgC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14815150302990230196", "cites_id": ["14815150302990230196"]}, "2hA4X9wAAAAJ:WA5NYHcadZ8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "StyleMaster: Towards flexible stylized image generation with diffusion models", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:WA5NYHcadZ8C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14856364155831484346", "cites_id": ["14856364155831484346"]}, "2hA4X9wAAAAJ:FAceZFleit8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rolermbench & rolerm: Towards reward modeling for profile-based role play in dialogue systems", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:FAceZFleit8C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8159506234888467933", "cites_id": ["8159506234888467933"]}, "2hA4X9wAAAAJ:YohjEiUPhakC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FeRA: Frequency-Energy Constrained Routing for Effective Diffusion Adaptation Fine-Tuning", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:YohjEiUPhakC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7913081991000794451", "cites_id": ["7913081991000794451"]}, "2hA4X9wAAAAJ:-FonjvnnhkoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Identity-preserving text-to-video generation guided by simple yet effective spatial-temporal decoupled representations", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:-FonjvnnhkoC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17850277013720886624", "cites_id": ["17850277013720886624"]}, "2hA4X9wAAAAJ:xtoqd-5pKcoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LLM-Oriented Token-Adaptive Knowledge Distillation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:xtoqd-5pKcoC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3198930237050399478", "cites_id": ["3198930237050399478"]}, "2hA4X9wAAAAJ:Ug5p-4gJ2f0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Human-MME: A Holistic Evaluation Benchmark for Human-Centric Multimodal Large Language Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:Ug5p-4gJ2f0C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18422331269678194708", "cites_id": ["18422331269678194708"]}, "2hA4X9wAAAAJ:HtEfBTGE9r8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual document understanding and reasoning: A multi-agent collaboration framework with agent-wise adaptive test-time scaling", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:HtEfBTGE9r8C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16377167189658911508", "cites_id": ["16377167189658911508"]}, "2hA4X9wAAAAJ:Dip1O2bNi0gC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HumanVideo-MME: Benchmarking MLLMs for Human-Centric Video Understanding", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:Dip1O2bNi0gC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10936561974460781463,17434051763343663360", "cites_id": ["10936561974460781463", "17434051763343663360"]}, "2hA4X9wAAAAJ:tYavs44e6CUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VTBench: Comprehensive Benchmark Suite Towards Real-World Virtual Try-on Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:tYavs44e6CUC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15009237061491151589", "cites_id": ["15009237061491151589"]}, "2hA4X9wAAAAJ:ILKRHgRFtOwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Align and surpass human camouflaged perception: Visual refocus reinforcement fine-tuning", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ILKRHgRFtOwC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9862880295627317280", "cites_id": ["9862880295627317280"]}, "2hA4X9wAAAAJ:hMsQuOkrut0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GroundingFace: Fine-grained Face Understanding via Pixel Grounding Multimodal Large Language Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:hMsQuOkrut0C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10075790455893057220", "cites_id": ["10075790455893057220"]}, "2hA4X9wAAAAJ:BwyfMAYsbu0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal industrial anomaly detection via hybrid fusion. 2022 IEEE", "pub_year": "2023"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:BwyfMAYsbu0C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11921068773814790743", "cites_id": ["11921068773814790743"]}, "2hA4X9wAAAAJ:NXb4pA-qfm4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The Landscape of Medical Agents: A Survey", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:NXb4pA-qfm4C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14738385826517745651", "cites_id": ["14738385826517745651"]}, "2hA4X9wAAAAJ:0izLItjtcgwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Soul: Breathe Life into Digital Human for High-fidelity Long-term Multimodal Animation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:0izLItjtcgwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15070572470712752519", "cites_id": ["15070572470712752519"]}, "2hA4X9wAAAAJ:9pM33mqn1YgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "InstanceV: Instance-Level Video Generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:9pM33mqn1YgC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7333094820022792214", "cites_id": ["7333094820022792214"]}, "2hA4X9wAAAAJ:86PQX7AUzd4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real-IAD Variety: Pushing Industrial Anomaly Detection Dataset to a Modern Era", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:86PQX7AUzd4C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9352661907479202673", "cites_id": ["9352661907479202673"]}, "2hA4X9wAAAAJ:SpbeaW3--B0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "StrandDesigner: Towards Practical Strand Generation with Sketch Guidance", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:SpbeaW3--B0C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16775546009414781144", "cites_id": ["16775546009414781144"]}, "2hA4X9wAAAAJ:LI9QrySNdTsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Semantic frame interpolation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:LI9QrySNdTsC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=586004404092101397", "cites_id": ["586004404092101397"]}, "2hA4X9wAAAAJ:WZBGuue-350C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:WZBGuue-350C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10165743055103454100", "cites_id": ["10165743055103454100"]}, "2hA4X9wAAAAJ:4MWp96NkSFoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Swin DiT: Diffusion Transformer using Pseudo Shifted Windows", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:4MWp96NkSFoC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4726913908055760299", "cites_id": ["4726913908055760299"]}, "2hA4X9wAAAAJ:epqYDVWIO7EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Image Inversion: A Survey from GANs to Diffusion and Beyond", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:epqYDVWIO7EC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2705671696921498341", "cites_id": ["2705671696921498341"]}, "2hA4X9wAAAAJ:kRWSkSYxWN8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DiffFAE: Advancing high-fidelity one-shot facial appearance editing with space-sensitive customization and semantic preservation", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:kRWSkSYxWN8C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3191591483822274504", "cites_id": ["3191591483822274504"]}, "2hA4X9wAAAAJ:VOx2b1Wkg3QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SelFSR: Self-Conditioned Face Super-Resolution in the Wild via Flow Field Degradation Network", "pub_year": "2021"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:VOx2b1Wkg3QC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17179573250384675307", "cites_id": ["17179573250384675307"]}, "2hA4X9wAAAAJ:uJ-U7cs_P_0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Knowledge rearranged multi-teacher distillation"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:uJ-U7cs_P_0C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6337522376339601072", "cites_id": ["6337522376339601072"]}, "2hA4X9wAAAAJ:_5tno0g5mFcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Large-Scale Multidimensional Knowledge Profiling of Scientific Literature", "pub_year": "2026"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:_5tno0g5mFcC", "num_citations": 0}, "2hA4X9wAAAAJ:DUooU5lO8OsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M3CoTBench: Benchmark Chain-of-Thought of MLLMs in Medical Image Understanding", "pub_year": "2026"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:DUooU5lO8OsC", "num_citations": 0}, "2hA4X9wAAAAJ:sNmaIFBj_lkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Generalized Multi-Image Editing for Unified Multimodal Models", "pub_year": "2026"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:sNmaIFBj_lkC", "num_citations": 0}, "2hA4X9wAAAAJ:umqufdRvDiIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Disco-RAG: Discourse-Aware Retrieval-Augmented Generation", "pub_year": "2026"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:umqufdRvDiIC", "num_citations": 0}, "2hA4X9wAAAAJ:XvxMoLDsR5gC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing", "pub_year": "2026"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:XvxMoLDsR5gC", "num_citations": 0}, "2hA4X9wAAAAJ:a9-T7VOCCH8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UltraLBM-UNet: Ultralight Bidirectional Mamba-based Model for Skin Lesion Segmentation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:a9-T7VOCCH8C", "num_citations": 0}, "2hA4X9wAAAAJ:bz8QjSJIRt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The devil is in the details: Enhancing Video Virtual Try-On via Keyframe-Driven Details Injection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:bz8QjSJIRt4C", "num_citations": 0}, "2hA4X9wAAAAJ:anf4URPfarAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Transform Trained Transformer: Accelerating Naive 4K Video Generation Over 10", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:anf4URPfarAC", "num_citations": 0}, "2hA4X9wAAAAJ:8d8msizDQcsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:8d8msizDQcsC", "num_citations": 0}, "2hA4X9wAAAAJ:_FM0Bhl9EiAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "One-to-All Animation: Alignment-Free Character Animation and Image Pose Transfe", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:_FM0Bhl9EiAC", "num_citations": 0}, "2hA4X9wAAAAJ:Ri6SYOTghG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Boosting Reasoning in Large Multimodal Models via Activation Replay", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:Ri6SYOTghG4C", "num_citations": 0}, "2hA4X9wAAAAJ:hCrLmN-GePgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ShortcutBreaker: Low-Rank Noisy Bottleneck with Global Perturbation Attention for Multi-Class Unsupervised Anomaly Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:hCrLmN-GePgC", "num_citations": 0}, "2hA4X9wAAAAJ:ClCfbGk0d_YC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TokenAR: Multiple Subject Generation via Autoregressive Token-level enhancement", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ClCfbGk0d_YC", "num_citations": 0}, "2hA4X9wAAAAJ:ruyezt5ZtCIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EfficientIML: Efficient High-Resolution Image Manipulation Localization", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ruyezt5ZtCIC", "num_citations": 0}, "2hA4X9wAAAAJ:XoXfffV-tXoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Explore Inversion and Invariance in Flow Transformer for General Conditional Generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:XoXfffV-tXoC", "num_citations": 0}, "2hA4X9wAAAAJ:4hFrxpcac9AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Collaborative Face Experts Fusion in Video Generation: Boosting Identity Consistency Across Large Face Poses", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:4hFrxpcac9AC", "num_citations": 0}, "2hA4X9wAAAAJ:i2xiXl-TujoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:i2xiXl-TujoC", "num_citations": 0}, "2hA4X9wAAAAJ:PoWvk5oyLR8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Explainable Bilingual Multimodal Misinformation Detection and Localization", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:PoWvk5oyLR8C", "num_citations": 0}, "2hA4X9wAAAAJ:gsN89kCJA0AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:gsN89kCJA0AC", "num_citations": 0}, "2hA4X9wAAAAJ:ML0RJ9NH7IQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MagicFace: Slot-Driven High-Fidelity One-Shot Facial Appearance Editing", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:ML0RJ9NH7IQC", "num_citations": 0}, "2hA4X9wAAAAJ:S16KYo8Pm5AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:S16KYo8Pm5AC", "num_citations": 0}, "2hA4X9wAAAAJ:kz9GbA2Ns4gC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ArtWeaver: Advanced Dynamic Style Integration via Diffusion Model", "pub_year": "2024"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:kz9GbA2Ns4gC", "num_citations": 0}, "2hA4X9wAAAAJ:2VqYfGB8ITEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HumanVideo-MME: Benchmarking MLLMs for Human-Centric Video Understanding"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:2VqYfGB8ITEC", "num_citations": 0}, "2hA4X9wAAAAJ:6ZxmRoH8BuwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Discourse-Aware Retrieval-Augmented Generation via Rhetorical Structure Modeling"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:6ZxmRoH8BuwC", "num_citations": 0}, "2hA4X9wAAAAJ:_axFR9aDTf0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Data-free VFX Self-Mining"}, "filled": false, "author_pub_id": "2hA4X9wAAAAJ:_axFR9aDTf0C", "num_citations": 0}}, "citedby5y": 5995, "hindex": 38, "hindex5y": 38, "i10index": 92, "i10index5y": 92, "cites_per_year": {"2020": 20, "2021": 83, "2022": 151, "2023": 401, "2024": 1266, "2025": 3574, "2026": 507}, "updated": "2026-02-22 08:36:18.775208"}